{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFgEKbCXqbSv"
      },
      "source": [
        "# MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbtTbxihqbSy"
      },
      "source": [
        "üéØ <b><u>Exercise objectives</u></b>\n",
        "- Understand the *MNIST* dataset \n",
        "- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n",
        "    - what are *Convolutional Layers*? \n",
        "    - how many *parameters* are involved in such a layer?\n",
        "- Train this CNN on images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_npj6bQqbSz"
      },
      "source": [
        "üöÄ <b><u>Let's get started!</u></b>\n",
        "\n",
        "Imagine that we are  back in time into the 90's.\n",
        "You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits? \n",
        "\n",
        "This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, [*Yann Le Cun*](https://en.wikipedia.org/wiki/Yann_LeCun), used to work.\n",
        "\n",
        "From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n",
        "\n",
        "> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuLHLdfBqbS0"
      },
      "source": [
        "![Number recognition](recognition.gif)\n",
        "\n",
        "*Note: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, once the CNN is trained, it will predict what digit is written. The inputs are the different digits and not one animation/video!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLFgJe99qbS0"
      },
      "source": [
        "ü§î <b><u>How does this CNN work ?</u></b>\n",
        "\n",
        "- *Inputs*: Images (_each image shows a handwritten digit_)\n",
        "- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n",
        "    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n",
        "\n",
        "üî¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the üìö [**MNIST dataset**](http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TAcFI2sIqbS1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJLLRA_nqbS2"
      },
      "source": [
        "## (1) The `MNIST` Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5o-3ScoqbS3"
      },
      "source": [
        "üìö Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n",
        "- *Vectors*: `boston_housing` (regression)\n",
        "- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n",
        "- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n",
        "\n",
        "\n",
        "üíæ You can **load the MNIST dataset** with the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seaYNq0oqbS3",
        "outputId": "9a71c044-2c25-4de5-9209-6a61ccefd2a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from tensorflow.keras import datasets\n",
        "\n",
        "\n",
        "# Loading the MNIST Dataset...\n",
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "\n",
        "# The train set contains 60 000 images, each of them of size 28x28\n",
        "# The test set contains 10 000 images, each of them of size 28x28\n",
        "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1bNuGG2qbS3"
      },
      "source": [
        "### (1.1) Exploring the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pcrYRYxqbS4"
      },
      "source": [
        "‚ùì **Question: Let's have look at some handwritten digits of this MNIST dataset.** ‚ùì\n",
        "\n",
        "üñ® Print some images from the *train set*.\n",
        "\n",
        "<details>\n",
        "    <summary><i>Hints</i></summary>\n",
        "\n",
        "üí°*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n",
        "\n",
        "ü§® Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just Matplotlib defaults...\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "85c9aXWjqbS4",
        "outputId": "ad320f24-af28-4783-b69a-fed243aa427c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7812d2d490>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(X_train[10], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4Le0WHjqbS4"
      },
      "source": [
        "### (1.2) Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_Y-FDNPqbS5"
      },
      "source": [
        "‚ùóÔ∏è **Neural Networks converge faster when the input data is somehow normalized** ‚ùóÔ∏è\n",
        "\n",
        "üë©üèª‚Äçüè´ How do we proceed for Convolutional Neural Networks ?\n",
        "* The `RBG` intensities are coded between 0 and 255. \n",
        "* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 üòâ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YGn2bSEqbS5"
      },
      "source": [
        "‚ùì **Question ‚ùì As a first preprocessing step, please normalize your data.** \n",
        "\n",
        "Don't forget to do it both on your train data and your test data.\n",
        "\n",
        "(*Note: you can also center your data, by subtracting 0.5 from all the values, but it is not mandatory*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "ClB5cFrXqbS6"
      },
      "outputs": [],
      "source": [
        "X_train = X_train/255.\n",
        "X_test = X_test/255. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTsPGmJkqbS6"
      },
      "source": [
        "### (1.3) Inputs' dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylji3MjjqbS6",
        "outputId": "0486d1f3-f0b2-431c-ff25-b040a243d206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjwuIlzCqbS6"
      },
      "source": [
        "üëÜ Remember that you have 60,000 training images and 10,000 test images, each of size $(28, 28)$. However...\n",
        "\n",
        "> ‚ùóÔ∏è  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`.**  \n",
        "\n",
        "> üßëüèª‚Äçüè´ The shape of tensors fed into ***ConvNets*** is the following: `(NUMBER_OF_IMAGES, HEIGHT, WIDTH, CHANNELS)`\n",
        "\n",
        "üïµüèªThis last dimension is clearly missing here. Can you guess the reason why?\n",
        "<br>\n",
        "<details>\n",
        "    <summary><i>Answer<i></summary>\n",
        "        \n",
        "* All these $60000$ $ (28 \\times 28) $ pictures are black-and-white $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1).\n",
        "        \n",
        "    * Theoretically, you don't need to know the number of channels for a black-and-white picture since there is only 1 channel (the \"whiteness\" of \"blackness\" of a pixel). However, it is still mandatory for the model to have this number of channels explicitly stated.\n",
        "        \n",
        "    * In comparison, colored pictures need multiple channels:\n",
        "        - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n",
        "        - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span></b>)\n",
        "        \n",
        "        \n",
        "</details>        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n0v3jU2qbS7"
      },
      "source": [
        "‚ùì **Question: expanding dimensions** ‚ùì\n",
        "\n",
        "* Use the **`expand_dims`** to add one dimension at the end of the training data and test data.\n",
        "\n",
        "* Then, print the shapes of `X_train` and `X_test`. They should respectively be equal to $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "je6Ds8AGuSD4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ViD6OxlqqbS7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.backend import expand_dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9qoe8pS_qbS7"
      },
      "outputs": [],
      "source": [
        "X_train = tf.keras.backend.expand_dims(X_train, -1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = tf.keras.backend.expand_dims(X_test, -1)"
      ],
      "metadata": {
        "id": "AhKzTXlpujB1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdgmh5ukqbS7"
      },
      "source": [
        "### (1.4) Target encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYJzQzfLqbS7"
      },
      "source": [
        "One more thing to for a multiclass classification task in Deep Leaning:\n",
        "\n",
        "üëâ _\"one-hot-encode\" the categories*_\n",
        "\n",
        "‚ùì **Question: encoding the labels** ‚ùì \n",
        "\n",
        "* Use **`to_categorical`** to transform your labels. \n",
        "* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mqutiyz3qbS8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_cat = tf.keras.utils.to_categorical(y_train)"
      ],
      "metadata": {
        "id": "zAjxC_uWuyod"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_cat = tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "MRaFpwuJvGuU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Zs-bgd1YqbS8"
      },
      "outputs": [],
      "source": [
        "# Quick check that you correctly used to_categorical\n",
        "assert(y_train_cat.shape == (60000,10))\n",
        "assert(y_test_cat.shape == (10000,10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NouD6sL2qbS8"
      },
      "source": [
        "The data is now ready to be used. ‚úÖ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5magAHNVqbS8"
      },
      "source": [
        "## (2) The Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmEozTCkqbS8"
      },
      "source": [
        "### (2.1) Architecture and compilation of a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY9Odv2cqbS8"
      },
      "source": [
        "\n",
        "‚ùì **Question: CNN Architecture and compilation** ‚ùì\n",
        "\n",
        "Now, let's build a <u>Convolutional Neural Network</u> that has: \n",
        "\n",
        "\n",
        "- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n",
        "- a `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "- a second `Conv2D` layer with 16 filters, each of size $(3, 3)$, and the `relu` activation function\n",
        "- a second `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "\n",
        "\n",
        "- a `Flatten` layer\n",
        "- a first `Dense` layer with 10 neurons and the `relu` activation function\n",
        "- a last (predictive) layer that is suited for your task\n",
        "\n",
        "In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n",
        "* optimizes the `categorical_crossentropy` loss function,\n",
        "* with the `adam` optimizer, \n",
        "* and the `accuracy` as the metrics\n",
        "\n",
        "(*Note: you could add more classification metrics if you want but the dataset is well balanced!*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lCtGjCBJqbS8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "\n",
        "def initialize_model():\n",
        "\n",
        "    model = models.Sequential()\n",
        "\n",
        "    ### First Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(8, (4,4), input_shape=(28,28,1), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    ### Second Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(16, (3,3), activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "    \n",
        "    ### Flattening\n",
        "    model.add(layers.Flatten())\n",
        "    \n",
        "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
        "    model.add(layers.Dense(10, activation='relu'))\n",
        "    \n",
        "    ### Last layer - Classification Layer with 10 outputs corresponding to 10 digits\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    \n",
        "    ### Model compilation\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwAdxw6kqbS9"
      },
      "source": [
        "‚ùì **Question: number of trainable parameters in a convolutional layer** ‚ùì \n",
        "\n",
        "How many trainable parameters are there in your model?\n",
        "1. Compute them with ***model.summary( )*** first\n",
        "2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "wxmpmUQFqbS9"
      },
      "outputs": [],
      "source": [
        "model = initialize_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq3xFg3QxN5Y",
        "outputId": "98417283-1fc6-4917-aaea-216f8a767891"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 8)         136       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 8)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 576)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5770      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,184\n",
            "Trainable params: 7,184\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "8*4*4 + 8 \n",
        "8*16*3*3 + 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp0yoEFbxk35",
        "outputId": "be2dd6b7-1696-4a19-cf9e-b8adf999c99c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1168"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzBblU2NqbS9"
      },
      "source": [
        "### (2.2) Training a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBzkNAtMqbS9"
      },
      "source": [
        "‚ùì **Question: training a CNN** ‚ùì \n",
        "\n",
        "Initialize your model and fit it on the train data. \n",
        "- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**. \n",
        "- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "c9kLIIiY0CVO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ySV0C9Ni0YDg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sxz1sBqqbS9",
        "outputId": "3955f2e9-e670-401e-f15c-08a7465612ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2625/2625 [==============================] - 18s 5ms/step - loss: 0.3033 - accuracy: 0.9025 - val_loss: 0.1314 - val_accuracy: 0.9602\n",
            "Epoch 2/5\n",
            "2625/2625 [==============================] - 12s 5ms/step - loss: 0.0980 - accuracy: 0.9702 - val_loss: 0.0845 - val_accuracy: 0.9737\n",
            "Epoch 3/5\n",
            "2625/2625 [==============================] - 12s 5ms/step - loss: 0.0713 - accuracy: 0.9775 - val_loss: 0.0822 - val_accuracy: 0.9749\n",
            "Epoch 4/5\n",
            "2625/2625 [==============================] - 12s 5ms/step - loss: 0.0572 - accuracy: 0.9822 - val_loss: 0.0637 - val_accuracy: 0.9811\n",
            "Epoch 5/5\n",
            "2625/2625 [==============================] - 13s 5ms/step - loss: 0.0479 - accuracy: 0.9849 - val_loss: 0.0673 - val_accuracy: 0.9796\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f781345acd0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "es = EarlyStopping(patience=20, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train, y_train_cat,\n",
        "          batch_size=16, \n",
        "          epochs=5, \n",
        "          validation_split=0.3,\n",
        "          callbacks=[es],\n",
        "          verbose=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he4HTy7fqbS-"
      },
      "source": [
        "‚ùì **Question: How many iterations does the CNN perform per epoch** ‚ùì\n",
        "\n",
        "_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting, and losses üòâ_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "aHkbfyv0qbS-"
      },
      "source": [
        "> YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3js_SUaMqbS-"
      },
      "source": [
        "<details>\n",
        "    <summary><i>Answer</i></summary>\n",
        "\n",
        "With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n",
        "    \n",
        "Remember that we've just trained our CNN model on $60000$ training images\n",
        "\n",
        "If the chosen batch size is 32: \n",
        "\n",
        "* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
        "* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n",
        "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss` \n",
        "    * $ 1875 - 1312 = 562 $ batches are used to compute the `val_loss`\n",
        "    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n",
        "\n",
        "\n",
        "üëâ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n",
        "\n",
        "</details>    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOWDA9XKqbS-"
      },
      "source": [
        "### (2.3) Evaluating its performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWpNkC3nqbS-"
      },
      "source": [
        "‚ùì **Question: Evaluating your CNN** ‚ùì \n",
        "\n",
        "What is your **`accuracy on the test set?`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wArPTdj4qbS-",
        "outputId": "574c73e8-45b6-4e90-d513-2a7e21eaa2e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0557 - accuracy: 0.9822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05565939471125603, 0.982200026512146]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test_cat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbIiouVdqbS-"
      },
      "source": [
        "üéâ You should already be impressed by your CNN skills! Reaching over 95% accuracy!\n",
        "\n",
        "üî• You solved what was a very hard problem 30 years ago with your own CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSyv-nLfqbS_"
      },
      "source": [
        "üèÅ **Congratulations!**\n",
        "\n",
        "üíæ Don't forget to `git add/commit/push` your notebook...\n",
        "\n",
        "üöÄ ... and move on to the next challenge!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}